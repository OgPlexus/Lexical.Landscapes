{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On All 1-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Initializations ---------------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### File Paths Definitions --------------------------------------------------------------\n",
    "\n",
    "files = [\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-a',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-b',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-c',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-d',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-e',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-f',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-g',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-h',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-i',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-j',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-k',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-l',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-m',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-n',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-o',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-p',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-q',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-r',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-s',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-t',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-u',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-v',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-w',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-x',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-y',\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-gb-all-1gram-20120701-z'\\\n",
    "        ]\n",
    "\n",
    "### Set Word Length -----------------------------------------------------------\n",
    "\n",
    "WORDLEN = 5\n",
    "\n",
    "\n",
    "### Import / Clean 'A' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfA = pd.read_csv(files[0],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfA.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfA.index.name = 'OneGram Count'\n",
    "dfA = dfA.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfA['OneGram'] = dfA['OneGram'].astype(str)\n",
    "\n",
    "dfA = dfA.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfA['OneGram'] = dfA['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfA['OneGram'] = dfA['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfA['OneGram'] = dfA['OneGram'].apply(ltrim)\n",
    "\n",
    "dfA = dfA[dfA.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfA['OneGram'] = dfA['OneGram'].apply(UpUp)\n",
    "\n",
    "dfA = dfA.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'B' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfB = pd.read_csv(files[1],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfB.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfB.index.name = 'OneGram Count'\n",
    "dfB = dfB.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfB['OneGram'] = dfB['OneGram'].astype(str)\n",
    "\n",
    "dfB = dfB.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfB['OneGram'] = dfB['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfB['OneGram'] = dfB['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfB['OneGram'] = dfB['OneGram'].apply(ltrim)\n",
    "\n",
    "dfB = dfB[dfB.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfB['OneGram'] = dfB['OneGram'].apply(UpUp)\n",
    "\n",
    "dfB = dfB.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'C' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfC = pd.read_csv(files[2],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfC.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfC.index.name = 'OneGram Count'\n",
    "dfC = dfC.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfC['OneGram'] = dfC['OneGram'].astype(str)\n",
    "\n",
    "dfC = dfC.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfC['OneGram'] = dfC['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfC['OneGram'] = dfC['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfC['OneGram'] = dfC['OneGram'].apply(ltrim)\n",
    "\n",
    "dfC = dfC[dfC.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfC['OneGram'] = dfC['OneGram'].apply(UpUp)\n",
    "\n",
    "dfC = dfC.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'D' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfD = pd.read_csv(files[3],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfD.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfD.index.name = 'OneGram Count'\n",
    "dfD = dfD.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfD['OneGram'] = dfD['OneGram'].astype(str)\n",
    "\n",
    "dfD = dfD.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfD['OneGram'] = dfD['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfD['OneGram'] = dfD['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfD['OneGram'] = dfD['OneGram'].apply(ltrim)\n",
    "\n",
    "dfD = dfD[dfD.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfD['OneGram'] = dfD['OneGram'].apply(UpUp)\n",
    "\n",
    "dfD = dfD.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'E' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfE = pd.read_csv(files[4],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfE.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfE.index.name = 'OneGram Count'\n",
    "dfE = dfE.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfE['OneGram'] = dfE['OneGram'].astype(str)\n",
    "\n",
    "dfE = dfE.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfE['OneGram'] = dfE['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfE['OneGram'] = dfE['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfE['OneGram'] = dfE['OneGram'].apply(ltrim)\n",
    "\n",
    "dfE = dfE[dfE.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfE['OneGram'] = dfE['OneGram'].apply(UpUp)\n",
    "\n",
    "dfE = dfE.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'F' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfF = pd.read_csv(files[5],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfF.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfF.index.name = 'OneGram Count'\n",
    "dfF = dfF.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfF['OneGram'] = dfF['OneGram'].astype(str)\n",
    "\n",
    "dfF = dfF.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfF['OneGram'] = dfF['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfF['OneGram'] = dfF['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfF['OneGram'] = dfF['OneGram'].apply(ltrim)\n",
    "\n",
    "dfF = dfF[dfF.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfF['OneGram'] = dfF['OneGram'].apply(UpUp)\n",
    "\n",
    "dfF = dfF.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'G' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfG = pd.read_csv(files[6],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfG.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfG.index.name = 'OneGram Count'\n",
    "dfG = dfG.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfG['OneGram'] = dfG['OneGram'].astype(str)\n",
    "\n",
    "dfG = dfG.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfG['OneGram'] = dfG['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfG['OneGram'] = dfG['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfG['OneGram'] = dfG['OneGram'].apply(ltrim)\n",
    "\n",
    "dfG = dfG[dfG.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfG['OneGram'] = dfG['OneGram'].apply(UpUp)\n",
    "\n",
    "dfG = dfG.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'H' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfH = pd.read_csv(files[7],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfH.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfH.index.name = 'OneGram Count'\n",
    "dfH = dfH.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfH['OneGram'] = dfH['OneGram'].astype(str)\n",
    "\n",
    "dfH = dfH.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfH['OneGram'] = dfH['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfH['OneGram'] = dfH['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfH['OneGram'] = dfH['OneGram'].apply(ltrim)\n",
    "\n",
    "dfH = dfH[dfH.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfH['OneGram'] = dfH['OneGram'].apply(UpUp)\n",
    "\n",
    "dfH = dfH.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'I' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfI = pd.read_csv(files[8],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfI.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfI.index.name = 'OneGram Count'\n",
    "dfI = dfI.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfI['OneGram'] = dfI['OneGram'].astype(str)\n",
    "\n",
    "dfI = dfI.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfI['OneGram'] = dfI['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfI['OneGram'] = dfI['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfI['OneGram'] = dfI['OneGram'].apply(ltrim)\n",
    "\n",
    "dfI = dfI[dfI.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfI['OneGram'] = dfI['OneGram'].apply(UpUp)\n",
    "\n",
    "dfI = dfI.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'J' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfJ = pd.read_csv(files[9],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfJ.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfJ.index.name = 'OneGram Count'\n",
    "dfJ = dfJ.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfJ['OneGram'] = dfJ['OneGram'].astype(str)\n",
    "\n",
    "dfJ = dfJ.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfJ['OneGram'] = dfJ['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfJ['OneGram'] = dfJ['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfJ['OneGram'] = dfJ['OneGram'].apply(ltrim)\n",
    "\n",
    "dfJ = dfJ[dfJ.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfJ['OneGram'] = dfJ['OneGram'].apply(UpUp)\n",
    "\n",
    "dfJ = dfJ.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'K' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfK = pd.read_csv(files[10],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfK.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfK.index.name = 'OneGram Count'\n",
    "dfK = dfK.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfK['OneGram'] = dfK['OneGram'].astype(str)\n",
    "\n",
    "dfK = dfK.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfK['OneGram'] = dfK['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfK['OneGram'] = dfK['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfK['OneGram'] = dfK['OneGram'].apply(ltrim)\n",
    "\n",
    "dfK = dfK[dfK.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfK['OneGram'] = dfK['OneGram'].apply(UpUp)\n",
    "\n",
    "dfK = dfK.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'L' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfL = pd.read_csv(files[11],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfL.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfL.index.name = 'OneGram Count'\n",
    "dfL = dfL.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfL['OneGram'] = dfL['OneGram'].astype(str)\n",
    "\n",
    "dfL = dfL.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfL['OneGram'] = dfL['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfL['OneGram'] = dfL['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfL['OneGram'] = dfL['OneGram'].apply(ltrim)\n",
    "\n",
    "dfL = dfL[dfL.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfL['OneGram'] = dfL['OneGram'].apply(UpUp)\n",
    "\n",
    "dfL = dfL.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'M' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfM = pd.read_csv(files[12],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfM.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfM.index.name = 'OneGram Count'\n",
    "dfM = dfM.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfM['OneGram'] = dfM['OneGram'].astype(str)\n",
    "\n",
    "dfM = dfM.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfM['OneGram'] = dfM['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfM['OneGram'] = dfM['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfM['OneGram'] = dfM['OneGram'].apply(ltrim)\n",
    "\n",
    "dfM = dfM[dfM.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfM['OneGram'] = dfM['OneGram'].apply(UpUp)\n",
    "\n",
    "dfM = dfM.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'N' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfN = pd.read_csv(files[13],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfN.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfN.index.name = 'OneGram Count'\n",
    "dfN = dfN.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfN['OneGram'] = dfN['OneGram'].astype(str)\n",
    "\n",
    "dfN = dfN.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfN['OneGram'] = dfN['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfN['OneGram'] = dfN['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfN['OneGram'] = dfN['OneGram'].apply(ltrim)\n",
    "\n",
    "dfN = dfN[dfN.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfN['OneGram'] = dfN['OneGram'].apply(UpUp)\n",
    "\n",
    "dfN = dfN.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'O' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfO = pd.read_csv(files[14],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfO.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfO.index.name = 'OneGram Count'\n",
    "dfO = dfO.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfO['OneGram'] = dfO['OneGram'].astype(str)\n",
    "\n",
    "dfO = dfO.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfO['OneGram'] = dfO['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfO['OneGram'] = dfO['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfO['OneGram'] = dfO['OneGram'].apply(ltrim)\n",
    "\n",
    "dfO = dfO[dfO.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfO['OneGram'] = dfO['OneGram'].apply(UpUp)\n",
    "\n",
    "dfO = dfO.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'P' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfP = pd.read_csv(files[15],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfP.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfP.index.name = 'OneGram Count'\n",
    "dfP = dfP.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfP['OneGram'] = dfP['OneGram'].astype(str)\n",
    "\n",
    "dfP = dfP.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfP['OneGram'] = dfP['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfP['OneGram'] = dfP['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfP['OneGram'] = dfP['OneGram'].apply(ltrim)\n",
    "\n",
    "dfP = dfP[dfP.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfP['OneGram'] = dfP['OneGram'].apply(UpUp)\n",
    "\n",
    "dfP = dfP.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'Q' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfQ = pd.read_csv(files[16],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfQ.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfQ.index.name = 'OneGram Count'\n",
    "dfQ = dfQ.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfQ['OneGram'] = dfQ['OneGram'].astype(str)\n",
    "\n",
    "dfQ = dfQ.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfQ['OneGram'] = dfQ['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfQ['OneGram'] = dfQ['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfQ['OneGram'] = dfQ['OneGram'].apply(ltrim)\n",
    "\n",
    "dfQ = dfQ[dfQ.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfQ['OneGram'] = dfQ['OneGram'].apply(UpUp)\n",
    "\n",
    "dfQ = dfQ.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'R' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfR = pd.read_csv(files[17],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfR.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfR.index.name = 'OneGram Count'\n",
    "dfR = dfR.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfR['OneGram'] = dfR['OneGram'].astype(str)\n",
    "\n",
    "dfR = dfR.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfR['OneGram'] = dfR['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfR['OneGram'] = dfR['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfR['OneGram'] = dfR['OneGram'].apply(ltrim)\n",
    "\n",
    "dfR = dfR[dfR.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfR['OneGram'] = dfR['OneGram'].apply(UpUp)\n",
    "\n",
    "dfR = dfR.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'S' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfS = pd.read_csv(files[18],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfS.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfS.index.name = 'OneGram Count'\n",
    "dfS = dfS.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfS['OneGram'] = dfS['OneGram'].astype(str)\n",
    "\n",
    "dfS = dfS.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfS['OneGram'] = dfS['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfS['OneGram'] = dfS['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfS['OneGram'] = dfS['OneGram'].apply(ltrim)\n",
    "\n",
    "dfS = dfS[dfS.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfS['OneGram'] = dfS['OneGram'].apply(UpUp)\n",
    "\n",
    "dfS = dfS.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'T' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfT = pd.read_csv(files[19],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfT.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfT.index.name = 'OneGram Count'\n",
    "dfT = dfT.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfT['OneGram'] = dfT['OneGram'].astype(str)\n",
    "\n",
    "dfT = dfT.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfT['OneGram'] = dfT['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfT['OneGram'] = dfT['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfT['OneGram'] = dfT['OneGram'].apply(ltrim)\n",
    "\n",
    "dfT = dfT[dfT.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfT['OneGram'] = dfT['OneGram'].apply(UpUp)\n",
    "\n",
    "dfT = dfT.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'U' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfU = pd.read_csv(files[20],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfU.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfU.index.name = 'OneGram Count'\n",
    "dfU = dfU.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfU['OneGram'] = dfU['OneGram'].astype(str)\n",
    "\n",
    "dfU = dfU.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfU['OneGram'] = dfU['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfU['OneGram'] = dfU['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfU['OneGram'] = dfU['OneGram'].apply(ltrim)\n",
    "\n",
    "dfU = dfU[dfU.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfU['OneGram'] = dfU['OneGram'].apply(UpUp)\n",
    "\n",
    "dfU = dfU.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'V' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfV = pd.read_csv(files[21],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfV.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfV.index.name = 'OneGram Count'\n",
    "dfV = dfV.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfV['OneGram'] = dfV['OneGram'].astype(str)\n",
    "\n",
    "dfV = dfV.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfV['OneGram'] = dfV['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfV['OneGram'] = dfV['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfV['OneGram'] = dfV['OneGram'].apply(ltrim)\n",
    "\n",
    "dfV = dfV[dfV.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfV['OneGram'] = dfV['OneGram'].apply(UpUp)\n",
    "\n",
    "dfV = dfV.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'W' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfW = pd.read_csv(files[22],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfW.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfW.index.name = 'OneGram Count'\n",
    "dfW = dfW.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfW['OneGram'] = dfW['OneGram'].astype(str)\n",
    "\n",
    "dfW = dfW.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfW['OneGram'] = dfW['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfW['OneGram'] = dfW['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfW['OneGram'] = dfW['OneGram'].apply(ltrim)\n",
    "\n",
    "dfW = dfW[dfW.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfW['OneGram'] = dfW['OneGram'].apply(UpUp)\n",
    "\n",
    "dfW = dfW.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'X' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfX = pd.read_csv(files[23],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfX.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfX.index.name = 'OneGram Count'\n",
    "dfX = dfX.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].astype(str)\n",
    "\n",
    "dfX = dfX.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(ltrim)\n",
    "\n",
    "dfX = dfX[dfX.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(UpUp)\n",
    "\n",
    "dfX = dfX.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'Y' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfY = pd.read_csv(files[24],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfY.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfY.index.name = 'OneGram Count'\n",
    "dfY = dfY.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfY['OneGram'] = dfY['OneGram'].astype(str)\n",
    "\n",
    "dfY = dfY.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfY['OneGram'] = dfY['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfY['OneGram'] = dfY['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfY['OneGram'] = dfY['OneGram'].apply(ltrim)\n",
    "\n",
    "dfY = dfY[dfY.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfY['OneGram'] = dfY['OneGram'].apply(UpUp)\n",
    "\n",
    "dfY = dfY.reset_index(drop =True)\n",
    "\n",
    "\n",
    "### Import / Clean 'Z' 1-Grams -----------------------------------------------------------\n",
    "\n",
    "dfZ = pd.read_csv(files[25],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfZ.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfZ.index.name = 'OneGram Count'\n",
    "dfZ = dfZ.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfZ['OneGram'] = dfZ['OneGram'].astype(str)\n",
    "\n",
    "dfZ = dfZ.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfZ['OneGram'] = dfZ['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfZ['OneGram'] = dfZ['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfZ['OneGram'] = dfZ['OneGram'].apply(ltrim)\n",
    "\n",
    "dfZ = dfZ[dfZ.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfZ['OneGram'] = dfZ['OneGram'].apply(UpUp)\n",
    "\n",
    "dfZ = dfZ.reset_index(drop =True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Merging / Concatination --------------------------------------------------------------\n",
    "\n",
    "dfList = [\\\n",
    "          dfA,\\\n",
    "          dfB,\\\n",
    "          dfC,\\\n",
    "          dfD,\\\n",
    "          dfE,\\\n",
    "          dfF,\\\n",
    "          dfG,\\\n",
    "          dfH,\\\n",
    "          dfI,\\\n",
    "          dfJ,\\\n",
    "          dfK,\\\n",
    "          dfL,\\\n",
    "          dfM,\\\n",
    "          dfN,\\\n",
    "          dfO,\\\n",
    "          dfP,\\\n",
    "          dfQ,\\\n",
    "          dfR,\\\n",
    "          dfS,\\\n",
    "          dfT,\\\n",
    "          dfU,\\\n",
    "          dfV,\\\n",
    "          dfW,\\\n",
    "          dfX,\\\n",
    "          dfY,\\\n",
    "          dfZ\\\n",
    "         ]\n",
    "\n",
    "dfAll = pd.concat([\\\n",
    "                   dfList[0],\\\n",
    "                   dfList[1],\\\n",
    "                   dfList[2],\\\n",
    "                   dfList[3],\\\n",
    "                   dfList[4],\\\n",
    "                   dfList[5],\\\n",
    "                   dfList[6],\\\n",
    "                   dfList[7],\\\n",
    "                   dfList[8],\\\n",
    "                   dfList[9],\\\n",
    "                   dfList[10],\\\n",
    "                   dfList[11],\\\n",
    "                   dfList[12],\\\n",
    "                   dfList[13],\\\n",
    "                   dfList[14],\\\n",
    "                   dfList[15],\\\n",
    "                   dfList[16],\\\n",
    "                   dfList[17],\\\n",
    "                   dfList[18],\\\n",
    "                   dfList[19],\\\n",
    "                   dfList[20],\\\n",
    "                   dfList[21],\\\n",
    "                   dfList[22],\\\n",
    "                   dfList[23],\\\n",
    "                   dfList[24],\\\n",
    "                   dfList[25]\\\n",
    "                  ], ignore_index=True)\n",
    "\n",
    "\n",
    "        \n",
    "### Trying To Clear Some Python 'Memory' Up --------------------------------------------------------------\n",
    "\n",
    "del files\n",
    "del dfList\n",
    "    \n",
    "del [[dfA,\\\n",
    "      dfB,\\\n",
    "      dfC,\\\n",
    "      dfD,\\\n",
    "      dfE,\\\n",
    "      dfF,\\\n",
    "      dfG,\\\n",
    "      dfH,\\\n",
    "      dfI,\\\n",
    "      dfJ,\\\n",
    "      dfK,\\\n",
    "      dfL,\\\n",
    "      dfM,\\\n",
    "      dfN,\\\n",
    "      dfO,\\\n",
    "      dfP,\\\n",
    "      dfQ,\\\n",
    "      dfR,\\\n",
    "      dfS,\\\n",
    "      dfT,\\\n",
    "      dfU,\\\n",
    "      dfV,\\\n",
    "      dfW,\\\n",
    "      dfX,\\\n",
    "      dfY,\\\n",
    "      dfZ\\\n",
    "     ]]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "dfA = pd.DataFrame()\n",
    "dfB = pd.DataFrame()\n",
    "dfC = pd.DataFrame()\n",
    "dfD = pd.DataFrame()\n",
    "dfE = pd.DataFrame()\n",
    "dfF = pd.DataFrame()\n",
    "dfG = pd.DataFrame()\n",
    "dfH = pd.DataFrame()\n",
    "dfI = pd.DataFrame()\n",
    "dfJ = pd.DataFrame()\n",
    "dfK = pd.DataFrame()\n",
    "dfL = pd.DataFrame()\n",
    "dfM = pd.DataFrame()\n",
    "dfN = pd.DataFrame()\n",
    "dfO = pd.DataFrame()\n",
    "dfP = pd.DataFrame()\n",
    "dfQ = pd.DataFrame()\n",
    "dfR = pd.DataFrame()\n",
    "dfS = pd.DataFrame()\n",
    "dfT = pd.DataFrame()\n",
    "dfU = pd.DataFrame()\n",
    "dfV = pd.DataFrame()\n",
    "dfW = pd.DataFrame()\n",
    "dfX = pd.DataFrame()\n",
    "dfY = pd.DataFrame()\n",
    "dfZ = pd.DataFrame()\n",
    "\n",
    "\n",
    "### Results Results This Sloppy Code Has Results ---------------------------------------------------------\n",
    "\n",
    "dfAll           ### Wall time: 59min 30s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Final Convert, Clean, & Save --------------------------------------------------------------------------\n",
    "\n",
    "# dfAll = dfAll.set_index(['OneGram', 'Year'], append=True).unstack()\n",
    "# dfAll = dfAll.fillna(0.0)\n",
    "# dfAll = dfAll.groupby(['OneGram']).sum() \n",
    "\n",
    "dfAll = dfAll.pivot_table(values = 'Count',\\\n",
    "                      columns = 'Year',\\\n",
    "                      index ='OneGram',\\\n",
    "                      fill_value =0,\\\n",
    "                      aggfunc=np.sum\\\n",
    "                     ).astype(int)\n",
    "\n",
    "# a = np.linspace(1700,2000,31)\n",
    "# a\n",
    "\n",
    "dfAll = dfAll[[1900., 1902., 1904., 1906., 1908., 1910., 1912., 1914., 1916.,\n",
    "               1918., 1920., 1922., 1924., 1926., 1928., 1930., 1932., 1934.,\n",
    "               1936., 1938., 1940., 1942., 1944., 1946., 1948., 1950., 1952.,\n",
    "               1954., 1956., 1958., 1960., 1962., 1964., 1966., 1968., 1970.,\n",
    "               1972., 1974., 1976., 1978., 1980., 1982., 1984., 1986., 1988.,\n",
    "               1990., 1992., 1994., 1996., 1998., 2000.]]\n",
    "\n",
    "dfAll['Total'] = dfAll.sum(axis=1)\n",
    "dfAll = dfAll.sort_values(by='Total', ascending=False)\n",
    "# dfAll = dfAll.reset_index()\n",
    "# dfAll = dfAll[dfAll.index <= 5000]\n",
    "dfAll = dfAll.drop(['Total'], axis=1)\n",
    "\n",
    "dfAll.to_csv(r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\The Array.csv')\n",
    "\n",
    "dfAll      ### Wall time: 9min 42s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some Basic Analysis Step 1 --------------------------------------------------------------------------------\n",
    "\n",
    "for dtype in ['float','int','object']:\n",
    "    selected_dtype = dfAll.select_dtypes(include=[dtype])\n",
    "    mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n",
    "    mean_usage_mb = mean_usage_b / 1024 ** 2\n",
    "    print(\"Average memory usage for {} columns: {:03.2f} MB\".format(dtype,mean_usage_mb))\n",
    "\n",
    "dfAll.info(memory_usage='deep')\n",
    "\n",
    "len(dfAll.OneGram.unique())\n",
    "\n",
    "dfAll.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some Basic Analysis Step 2 --------------------------------------------------------------------------------\n",
    "\n",
    "for dtype in ['float','int','object']:\n",
    "    selected_dtype = dfAll.select_dtypes(include=[dtype])\n",
    "    mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n",
    "    mean_usage_mb = mean_usage_b / 1024 ** 2\n",
    "    print(\"Average memory usage for {} columns: {:03.2f} MB\".format(dtype,mean_usage_mb))\n",
    "\n",
    "dfAll.info(memory_usage='deep')\n",
    "\n",
    "#len(dfAll.OneGram.unique())\n",
    "\n",
    "dfAll.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just On X 1-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = [\\\n",
    "         r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\googlebooks-eng-all-1gram-20120701-x',\\\n",
    "        ]\n",
    "\n",
    "WORDLEN = 4\n",
    "\n",
    "dfX = pd.read_csv(files[0],sep ='\\t', lineterminator ='\\n',header =None)\n",
    "\n",
    "dfX.columns = ['OneGram', 'Year', 'Count', 'Volume Count']\n",
    "dfX.index.name = 'OneGram Count'\n",
    "dfX = dfX.drop(labels='Volume Count', axis=1)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].astype(str)\n",
    "\n",
    "dfX = dfX.reset_index(drop =True)\n",
    "\n",
    "def cutter(s):\n",
    "    head, sep, tail = s.partition('_')\n",
    "    return(head)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(cutter)\n",
    "\n",
    "def letrdrop(s):\n",
    "    if re.match('^[a-zA-Z]+$', s):\n",
    "        return(s)\n",
    "    else:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(letrdrop)\n",
    "\n",
    "def ltrim(s):\n",
    "    if isinstance(s, int) == True:\n",
    "        return(s)\n",
    "    elif len(s) != WORDLEN:\n",
    "        s = int(0)\n",
    "        return(s)\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(ltrim)\n",
    "\n",
    "dfX = dfX[dfX.OneGram != 0]\n",
    "\n",
    "def UpUp(s):\n",
    "    Done = s.upper()\n",
    "    return(Done)\n",
    "\n",
    "dfX['OneGram'] = dfX['OneGram'].apply(UpUp)\n",
    "\n",
    "dfX = dfX.reset_index(drop =True)\n",
    "\n",
    "dfX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dfX = dfX.set_index(['OneGram', 'Year'], append=True).unstack()\n",
    "# dfX = dfX.fillna(0.0)\n",
    "# dfX = dfX.groupby(['OneGram']).sum() \n",
    "\n",
    "dfX = dfX.pivot_table(values = 'Count',\\\n",
    "                      columns = 'Year',\\\n",
    "                      index ='OneGram',\\\n",
    "                      fill_value =0,\\\n",
    "                      aggfunc=np.sum\\\n",
    "                     ).astype(int)\n",
    "\n",
    "# a = np.linspace(1700,2000,31)\n",
    "# a\n",
    "\n",
    "dfX = dfX[[1900., 1902., 1904., 1906., 1908., 1910., 1912., 1914., 1916.,\n",
    "           1918., 1920., 1922., 1924., 1926., 1928., 1930., 1932., 1934.,\n",
    "           1936., 1938., 1940., 1942., 1944., 1946., 1948., 1950., 1952.,\n",
    "           1954., 1956., 1958., 1960., 1962., 1964., 1966., 1968., 1970.,\n",
    "           1972., 1974., 1976., 1978., 1980., 1982., 1984., 1986., 1988.,\n",
    "           1990., 1992., 1994., 1996., 1998., 2000.]]\n",
    "\n",
    "dfX['Total'] = dfX.sum(axis=1)\n",
    "dfX = dfX.sort_values(by='Total', ascending=False)\n",
    "# dfX = dfX.reset_index()\n",
    "# dfX = dfX[dfX.index <= 5000]\n",
    "dfX = dfX.drop(['Total'], axis=1)\n",
    "\n",
    "dfX.to_csv(r'C:\\Users\\Victor\\Desktop\\1 Gram Data\\The Array.csv')\n",
    "\n",
    "dfX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
